{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from evolutron.tools import load_dataset, none2str, Handle, shape, get_args\n",
    "from evolutron.engine import Model\n",
    "from evolutron.templates import callback_templates as cb\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Convolution1D, MaxPooling1D, Dense, Flatten, Reshape\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from evolutron.extra_layers import Dedense, Upsampling1D, Deconvolution1D\n",
    "\n",
    "from keras.metrics import categorical_accuracy\n",
    "from evolutron.extra_metrics import mean_cat_acc\n",
    "\n",
    "from keras.losses import mean_squared_error, categorical_crossentropy\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "    \n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 4306\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('ecoli',padded=True)\n",
    "input_shape = (100, 20)\n",
    "seq_length, alphabet = input_shape\n",
    "filters = 15\n",
    "filter_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network has 6290 trainable parameters\n",
      "  #  Name             Shape      Parameters\n",
      "---  ---------------  -------  ------------\n",
      "  0  aa_seq           100x20              0\n",
      "  1  Conv             100x15           6015\n",
      "  2  max_pooling1d_1  1x15                0\n",
      "  3  flatten_1        15                  0\n",
      "  4  FCEnc            15                240\n",
      "  5  FCDec            15                 15\n",
      "  6  reshape_1        1x15                0\n",
      "  7  Upsampling       100x15              0\n",
      "  8  Deconv           100x20             20\n"
     ]
    }
   ],
   "source": [
    "# Input LayerRO\n",
    "inp = Input(shape=input_shape, name='aa_seq')\n",
    "\n",
    "# Convolutional Layers\n",
    "conv = Convolution1D(filters=filters,\n",
    "                       kernel_size=filter_length,\n",
    "                       kernel_initializer='glorot_uniform',\n",
    "                       activation='relu',\n",
    "                       padding='same',\n",
    "                       name='Conv')(inp)\n",
    "\n",
    "\n",
    "max_pool = MaxPooling1D(pool_size=seq_length)(conv)\n",
    "flat = Flatten()(max_pool)\n",
    "\n",
    "# Fully-Connected encoding layers\n",
    "encoded = Dense(filters,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                activation='sigmoid',\n",
    "                name='FCEnc')(flat)\n",
    "\n",
    "\n",
    "fc_dec = Dedense(encoded._keras_history[0],\n",
    "                  activation='linear',\n",
    "                  name='FCDec')(encoded)\n",
    "\n",
    "\n",
    "\n",
    "unflat = Reshape(max_pool._keras_shape[1:])(fc_dec)\n",
    "\n",
    "\n",
    "upsample = Upsampling1D(max_pool._keras_history[0].input_shape[1], name='Upsampling')(unflat)\n",
    "\n",
    "decoded = Deconvolution1D(conv._keras_history[0],\n",
    "                          apply_mask=False,\n",
    "                          activation='sigmoid',\n",
    "                          name='Deconv')(upsample)\n",
    "\n",
    "model = Model(inputs=inp, outputs=decoded, name='DeepCoDER', classification=False)\n",
    "\n",
    "losses = [mean_squared_error]\n",
    "\n",
    "# Metrics\n",
    "metrics = [mean_cat_acc]\n",
    "\n",
    "# Compilation\n",
    "\n",
    "model.compile(optimizer='nadam',\n",
    "              loss=losses,\n",
    "              metrics=metrics,\n",
    "              lr=.002)\n",
    "\n",
    "model.display_network_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing save and load on untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: test\n"
     ]
    }
   ],
   "source": [
    "model.save('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from evolutron.extra_layers import custom_layers\n",
    "from evolutron.engine import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = load_model('test', custom_objects=custom_layers, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
