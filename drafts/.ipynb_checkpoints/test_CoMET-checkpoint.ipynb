{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX 1080 (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "os.chdir('../CoMET')\n",
    "\n",
    "import evolutron.networks as nets\n",
    "from evolutron.motifs import motif_extraction\n",
    "from evolutron.tools import load_dataset, none2str, Handle, shape\n",
    "from evolutron.engine import DeepTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data and model\n",
    "data_id = 'zinc'\n",
    "padded = True\n",
    "mode = 'unsuper'\n",
    "model = None\n",
    "\n",
    "# Architecture\n",
    "n_filters = 100\n",
    "filter_length = 30\n",
    "n_convs = 1\n",
    "n_fc = 1\n",
    "\n",
    "# Training\n",
    "num_epochs = 20\n",
    "batch_size = 50\n",
    "optimizer = 'nadam'\n",
    "rate = .1\n",
    "validate = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 11906\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(data_id, padded=padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = dataset\n",
    "# Find input shape\n",
    "if type(x_data) == np.ndarray:\n",
    "    input_shape = x_data[0].shape\n",
    "elif type(x_data) == list:\n",
    "    input_shape = (None, x_data[0].shape[1])\n",
    "else:\n",
    "    raise TypeError('Something went wrong with the dataset type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model ...\n"
     ]
    }
   ],
   "source": [
    "print('Building model ...')\n",
    "net_arch = nets.DeepCoDER.from_options(input_shape, n_conv_layers=n_convs, n_fc_layers=n_fc,\n",
    "                                       n_filters=n_filters, filter_length=filter_length)\n",
    "conv_net = DeepTrainer(net_arch)\n",
    "conv_net.compile(optimizer=optimizer, lr=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network has 70320 trainable parameters\n",
      "  #  Name            Shape       Parameters\n",
      "---  --------------  --------  ------------\n",
      "  0  aa_seq          7182x20              0\n",
      "  1  masking_1       7182x20              0\n",
      "  2  Conv1           7182x100         60100\n",
      "  3  maxpooling1d_1  1x100                0\n",
      "  4  flatten_1       100                  0\n",
      "  5  FCEnc1          100              10100\n",
      "  6  FCDec1          100                100\n",
      "  7  reshape_1       1x100                0\n",
      "  8  Unpooling       7182x100             0\n",
      "  9  Deconv1         7182x20             20\n"
     ]
    }
   ],
   "source": [
    "conv_net.display_network_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training at Fri Nov 11 19:52:46 2016\n",
      "Train on 8572 samples, validate on 2143 samples\n",
      "Epoch 1/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.1825 - mean_cat_acc: 0.9251Epoch 00000: val_loss improved from inf to 0.14314, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 58s - loss: 0.1825 - mean_cat_acc: 0.9250 - val_loss: 0.1431 - val_mean_cat_acc: 0.9286\n",
      "Epoch 2/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.1203 - mean_cat_acc: 0.9279Epoch 00001: val_loss improved from 0.14314 to 0.10525, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.1202 - mean_cat_acc: 0.9279 - val_loss: 0.1052 - val_mean_cat_acc: 0.9303\n",
      "Epoch 3/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0923 - mean_cat_acc: 0.9291Epoch 00002: val_loss improved from 0.10525 to 0.08421, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0922 - mean_cat_acc: 0.9292 - val_loss: 0.0842 - val_mean_cat_acc: 0.9310\n",
      "Epoch 4/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0779 - mean_cat_acc: 0.9302Epoch 00003: val_loss improved from 0.08421 to 0.07170, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0779 - mean_cat_acc: 0.9302 - val_loss: 0.0717 - val_mean_cat_acc: 0.9333\n",
      "Epoch 5/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0689 - mean_cat_acc: 0.9319Epoch 00004: val_loss improved from 0.07170 to 0.06489, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0689 - mean_cat_acc: 0.9320 - val_loss: 0.0649 - val_mean_cat_acc: 0.9346\n",
      "Epoch 6/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0632 - mean_cat_acc: 0.9326Epoch 00005: val_loss improved from 0.06489 to 0.05998, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0632 - mean_cat_acc: 0.9326 - val_loss: 0.0600 - val_mean_cat_acc: 0.9351\n",
      "Epoch 7/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0580 - mean_cat_acc: 0.9334Epoch 00006: val_loss improved from 0.05998 to 0.05472, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0580 - mean_cat_acc: 0.9335 - val_loss: 0.0547 - val_mean_cat_acc: 0.9363\n",
      "Epoch 8/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0531 - mean_cat_acc: 0.9351Epoch 00007: val_loss improved from 0.05472 to 0.05072, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0531 - mean_cat_acc: 0.9350 - val_loss: 0.0507 - val_mean_cat_acc: 0.9382\n",
      "Epoch 9/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0497 - mean_cat_acc: 0.9369Epoch 00008: val_loss improved from 0.05072 to 0.04806, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0497 - mean_cat_acc: 0.9370 - val_loss: 0.0481 - val_mean_cat_acc: 0.9398\n",
      "Epoch 10/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0476 - mean_cat_acc: 0.9382Epoch 00009: val_loss improved from 0.04806 to 0.04640, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0476 - mean_cat_acc: 0.9381 - val_loss: 0.0464 - val_mean_cat_acc: 0.9405\n",
      "Epoch 11/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0462 - mean_cat_acc: 0.9385Epoch 00010: val_loss improved from 0.04640 to 0.04522, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 54s - loss: 0.0462 - mean_cat_acc: 0.9385 - val_loss: 0.0452 - val_mean_cat_acc: 0.9409\n",
      "Epoch 12/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0450 - mean_cat_acc: 0.9392Epoch 00011: val_loss improved from 0.04522 to 0.04419, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0450 - mean_cat_acc: 0.9391 - val_loss: 0.0442 - val_mean_cat_acc: 0.9414\n",
      "Epoch 13/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0442 - mean_cat_acc: 0.9394Epoch 00012: val_loss improved from 0.04419 to 0.04339, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0442 - mean_cat_acc: 0.9394 - val_loss: 0.0434 - val_mean_cat_acc: 0.9418\n",
      "Epoch 14/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0434 - mean_cat_acc: 0.9397Epoch 00013: val_loss improved from 0.04339 to 0.04271, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0434 - mean_cat_acc: 0.9398 - val_loss: 0.0427 - val_mean_cat_acc: 0.9421\n",
      "Epoch 15/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0427 - mean_cat_acc: 0.9403Epoch 00014: val_loss improved from 0.04271 to 0.04199, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0427 - mean_cat_acc: 0.9403 - val_loss: 0.0420 - val_mean_cat_acc: 0.9427\n",
      "Epoch 16/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0420 - mean_cat_acc: 0.9409Epoch 00015: val_loss improved from 0.04199 to 0.04128, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0420 - mean_cat_acc: 0.9409 - val_loss: 0.0413 - val_mean_cat_acc: 0.9434\n",
      "Epoch 17/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0413 - mean_cat_acc: 0.9415Epoch 00016: val_loss improved from 0.04128 to 0.04068, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0413 - mean_cat_acc: 0.9415 - val_loss: 0.0407 - val_mean_cat_acc: 0.9439\n",
      "Epoch 18/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0407 - mean_cat_acc: 0.9421Epoch 00017: val_loss improved from 0.04068 to 0.04010, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0407 - mean_cat_acc: 0.9420 - val_loss: 0.0401 - val_mean_cat_acc: 0.9445\n",
      "Epoch 19/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0402 - mean_cat_acc: 0.9426Epoch 00018: val_loss improved from 0.04010 to 0.03965, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0402 - mean_cat_acc: 0.9426 - val_loss: 0.0397 - val_mean_cat_acc: 0.9448\n",
      "Epoch 20/20\n",
      "8550/8572 [============================>.] - ETA: 0s - loss: 0.0398 - mean_cat_acc: 0.9431Epoch 00019: val_loss improved from 0.03965 to 0.03923, saving model to /tmp/best_0.6266421296103689.h5\n",
      "8572/8572 [==============================] - 53s - loss: 0.0398 - mean_cat_acc: 0.9431 - val_loss: 0.0392 - val_mean_cat_acc: 0.9458\n",
      "Model trained for 20 epochs. Total time: 1078.762s\n"
     ]
    }
   ],
   "source": [
    "print('Started training at {}'.format(time.asctime()))\n",
    "conv_net.fit(x_data[:int(.9 * len(x_data))], x_data[:int(.9 * len(x_data))],\n",
    "             nb_epoch=num_epochs,\n",
    "             batch_size=batch_size,\n",
    "             validate=validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1191/1191 [==============================] - 3s     \n",
      "Test Loss:0.039633, Test Accuracy: 94.13%\n"
     ]
    }
   ],
   "source": [
    "score = conv_net.score(x_data[int(.9 * len(x_data)):], x_data[int(.9 * len(x_data)):])\n",
    "print('Test Loss:{0:.6f}, Test Accuracy: {1:.2f}%'.format(score[0], 100*score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in:models/zinc/100_30_20_50_realDeepCoDER.model\n"
     ]
    }
   ],
   "source": [
    "handle = Handle(batch_size=batch_size,\n",
    "        filter_size=filter_length,\n",
    "        filters=n_filters,\n",
    "        program='CoMET',\n",
    "        dataset=data_id,\n",
    "        extra=None)\n",
    "handle.model = 'realDeepCoDER'\n",
    "conv_net.save_train_history(handle)\n",
    "conv_net.save_model_to_file(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
