{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "from keras.layers import Input, Convolution1D, MaxPooling1D, UpSampling1D, Masking\n",
    "from keras.models import Layer, Model\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "seed=6\n",
    "np.random.seed(seed)\n",
    "\n",
    "import os\n",
    "os.chdir('..')\n",
    "from evolutron.networks import Deconvolution1D, Unpooling1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa_length=15\n",
    "filter_length=3\n",
    "nb_filter=2\n",
    "alphabet=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv = Convolution1D(nb_filter, filter_length,\n",
    "                               init='glorot_normal',\n",
    "                               activation='relu',\n",
    "                               border_mode='same',\n",
    "                               name='Conv1')\n",
    "\n",
    "maxpool = MaxPooling1D(pool_length=aa_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unpool = Unpooling1D(maxpool)\n",
    "mask = Masking(mask_value=0.0)\n",
    "deconv = Deconvolution1D(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(aa_length, alphabet), name='aa_seq')\n",
    "x_data = np.random.random((10, 10, 4))\n",
    "x_data = np.pad(x_data, ((0,0), (0,5), (0,0)), 'constant', constant_values=0)\n",
    "x_data = x_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_m = mask(inp)\n",
    "x_c = conv(x_m)\n",
    "x_p = maxpool(x_c)\n",
    "x_u = unpool(x_p)\n",
    "x_d = deconv(x_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coder = Model(input=inp, output=x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "aa_seq (InputLayer)              (None, 15, 4)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "masking_1 (Masking)              (None, 15, 4)         0           aa_seq[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "Conv1 (Convolution1D)            (None, 15, 2)         26          masking_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 1, 2)          0           Conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "unpooling1d_1 (Unpooling1D)      (None, 15, 2)         0           maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution1d_1 (Deconvolution1(None, 15, 4)         4           unpooling1d_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 30\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "coder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s - loss: 0.3103\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s - loss: 0.3075\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s - loss: 0.3048\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s - loss: 0.3021\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s - loss: 0.2994\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s - loss: 0.2968\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s - loss: 0.2942\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s - loss: 0.2916\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s - loss: 0.2890\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s - loss: 0.2864\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s - loss: 0.2839\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s - loss: 0.2814\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s - loss: 0.2789\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s - loss: 0.2764\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s - loss: 0.2739\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s - loss: 0.2715\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s - loss: 0.2691\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s - loss: 0.2666\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s - loss: 0.2643\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s - loss: 0.2620\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s - loss: 0.2597\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s - loss: 0.2575\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s - loss: 0.2552\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s - loss: 0.2530\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s - loss: 0.2508\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s - loss: 0.2487\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s - loss: 0.2465\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s - loss: 0.2444\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s - loss: 0.2424\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s - loss: 0.2403\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s - loss: 0.2383\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s - loss: 0.2362\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s - loss: 0.2342\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s - loss: 0.2322\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s - loss: 0.2302\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s - loss: 0.2283\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s - loss: 0.2264\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s - loss: 0.2245\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s - loss: 0.2226\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s - loss: 0.2208\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s - loss: 0.2189\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s - loss: 0.2171\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s - loss: 0.2153\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s - loss: 0.2135\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s - loss: 0.2117\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s - loss: 0.2100\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s - loss: 0.2082\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s - loss: 0.2065\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s - loss: 0.2048\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s - loss: 0.2031\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s - loss: 0.2014\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s - loss: 0.1997\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s - loss: 0.1981\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s - loss: 0.1965\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s - loss: 0.1948\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s - loss: 0.1932\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s - loss: 0.1916\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s - loss: 0.1900\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s - loss: 0.1885\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s - loss: 0.1869\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s - loss: 0.1854\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s - loss: 0.1838\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s - loss: 0.1823\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s - loss: 0.1808\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s - loss: 0.1794\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s - loss: 0.1779\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s - loss: 0.1764\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s - loss: 0.1750\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s - loss: 0.1736\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s - loss: 0.1722\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s - loss: 0.1708\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s - loss: 0.1694\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s - loss: 0.1681\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s - loss: 0.1667\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s - loss: 0.1654\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s - loss: 0.1641\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s - loss: 0.1628\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s - loss: 0.1615\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s - loss: 0.1602\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s - loss: 0.1590\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s - loss: 0.1577\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s - loss: 0.1565\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s - loss: 0.1553\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s - loss: 0.1541\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s - loss: 0.1529\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s - loss: 0.1517\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s - loss: 0.1506\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s - loss: 0.1494\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s - loss: 0.1483\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s - loss: 0.1471\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s - loss: 0.1460\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s - loss: 0.1449\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s - loss: 0.1439\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s - loss: 0.1428\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s - loss: 0.1417\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s - loss: 0.1407\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s - loss: 0.1396\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s - loss: 0.1386\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s - loss: 0.1376\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s - loss: 0.1366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10c7b16d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coder.fit(x_data, x_data, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89286017  0.33197981  0.8212291   0.04169663]\n",
      " [ 0.10765668  0.59505206  0.52981734  0.41880742]\n",
      " [ 0.33540785  0.62251943  0.43814144  0.7358821 ]\n",
      " [ 0.51803643  0.57885861  0.64535511  0.99022424]\n",
      " [ 0.81985819  0.41320094  0.87626767  0.82375944]\n",
      " [ 0.05447451  0.71863723  0.80217057  0.73640662]\n",
      " [ 0.70913178  0.54093683  0.12482417  0.95764732]\n",
      " [ 0.4032563   0.21695116  0.71727586  0.99420744]\n",
      " [ 0.25561404  0.67130941  0.59900594  0.71733212]\n",
      " [ 0.93734956  0.35180977  0.2536341   0.4024725 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "[[ 0.35977209  0.29158431  0.39087862  0.63980585]\n",
      " [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      " [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      " [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      " [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      " [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      " [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      " [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      " [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      " [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "10/10 [==============================] - 0s\n",
      "0.135643854737\n"
     ]
    }
   ],
   "source": [
    "print(x_data.squeeze()[0])\n",
    "print(coder.predict(x_data).squeeze()[0])\n",
    "print(coder.evaluate(x_data, x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.090429239"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.square(x_data-coder.predict(x_data)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_c = K.function([inp], x_c)\n",
    "f_p = K.function([inp], x_p)\n",
    "f_u = K.function([inp], x_u)\n",
    "f_m = K.function([inp], x_m)\n",
    "f_d = K.function([inp], x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_c = f_c([np.expand_dims(x_data[0],0)])\n",
    "v_p = f_p([np.expand_dims(x_data[0],0)])\n",
    "v_u = f_u([np.expand_dims(x_data[0],0)])\n",
    "v_m = f_m([np.expand_dims(x_data[0],0)])\n",
    "v_d = f_d([np.expand_dims(x_data[0],0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 15, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_d = K.function([inp], x_d)\n",
    "v_d = f_d([x_data])\n",
    "v_d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import theano\n",
    "import theano.tensor as ten\n",
    "import lasagne\n",
    "\n",
    "las_inp_var = ten.tensor3('aa_seq', dtype=theano.config.floatX)\n",
    "las_target = ten.tensor3('aa_rec_seq', dtype=theano.config.floatX)\n",
    "\n",
    "las_inp = lasagne.layers.InputLayer(input_var=las_inp_var,\n",
    "                                    shape=(None,alphabet,aa_length),\n",
    "                                    name='Input')\n",
    "las_conv = lasagne.layers.Conv1DLayer(las_inp,\n",
    "                                     num_filters=nb_filter,\n",
    "                                     filter_size=filter_length,\n",
    "                                     flip_filters=False,\n",
    "                                     nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                                     W=lasagne.init.GlorotUniform('relu'),\n",
    "                                     stride=1,\n",
    "                                     pad='full',\n",
    "                                     name='Conv1')\n",
    "\n",
    "las_maxpool = lasagne.layers.MaxPool1DLayer(las_conv, pool_size=aa_length,\n",
    "                                          name='MaxPool')\n",
    "las_unpool = lasagne.layers.InverseLayer(las_maxpool, las_maxpool, name='inv_pool')\n",
    "\n",
    "las_deconv= lasagne.layers.InverseLayer(las_unpool, las_conv, name='inv_conv')\n",
    "\n",
    "prediction = lasagne.layers.get_output(las_deconv)\n",
    "loss = lasagne.objectives.squared_error(prediction, las_target)\n",
    "loss = loss.mean()\n",
    "\n",
    "test_prediction = lasagne.layers.get_output(las_deconv, deterministic=True)\n",
    "test_loss = lasagne.objectives.squared_error(test_prediction, las_target)\n",
    "test_loss = test_loss.mean()\n",
    "\n",
    "params = lasagne.layers.get_all_params(las_deconv, trainable=True)\n",
    "updates = lasagne.updates.adam(loss, params)\n",
    "\n",
    "train_fn = theano.function(inputs=[las_inp_var, las_target],\n",
    "                           outputs=[loss],\n",
    "                           updates=updates,\n",
    "                           allow_input_downcast=False)\n",
    "\n",
    "test_fn = theano.function(inputs=[las_inp_var, las_target],\n",
    "                          outputs=[test_loss],\n",
    "                          allow_input_downcast=False)\n",
    "\n",
    "pred_fn = theano.function(inputs=[las_inp_var],\n",
    "                          outputs=[test_prediction],\n",
    "                          allow_input_downcast=False)\n",
    "\n",
    "lf_c = theano.function(inputs=[las_inp_var],\n",
    "                       outputs=[lasagne.layers.get_output(las_conv)],\n",
    "                       allow_input_downcast=False)\n",
    "\n",
    "lf_p = theano.function(inputs=[las_inp_var],\n",
    "                       outputs=[lasagne.layers.get_output(las_maxpool)],\n",
    "                       allow_input_downcast=False)\n",
    "lf_u = theano.function(inputs=[las_inp_var],\n",
    "                       outputs=[lasagne.layers.get_output(las_unpool)],\n",
    "                       allow_input_downcast=False)\n",
    "lf_d = theano.function(inputs=[las_inp_var],\n",
    "                       outputs=[lasagne.layers.get_output(las_deconv)],\n",
    "                       allow_input_downcast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(0,100):\n",
    "    print(train_fn(x_data.transpose((0,2,1)), x_data.transpose((0,2,1)))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lv_c = lf_c([x_data[0].T])[0].squeeze()\n",
    "lv_p = lf_p([x_data[0].T])[0].squeeze()\n",
    "lv_u = lf_u([x_data[0].T])[0].squeeze()\n",
    "lv_d = lf_d([x_data[0].T])[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -3.72529030e-09   7.81332314e-01]\n",
      "  [ -3.72529030e-09   5.53094864e-01]\n",
      "  [ -3.72529030e-09   8.66643071e-01]\n",
      "  [ -3.72529030e-09   9.01467562e-01]\n",
      "  [ -3.72529030e-09   1.03664315e+00]\n",
      "  [ -3.72529030e-09   8.03544819e-01]\n",
      "  [  1.11758709e-08   9.14665043e-01]\n",
      "  [ -3.72529030e-09   7.25457609e-01]\n",
      "  [ -3.72529030e-09   6.37077332e-01]\n",
      "  [ -3.72529030e-09   5.16717672e-01]\n",
      "  [ -3.72529030e-09   0.00000000e+00]\n",
      "  [  0.00000000e+00   0.00000000e+00]\n",
      "  [  0.00000000e+00   0.00000000e+00]\n",
      "  [  0.00000000e+00   0.00000000e+00]\n",
      "  [  0.00000000e+00   0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(v_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1.11758709e-08   1.03664315e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(v_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]\n",
      "  [  1.11758709e-08   1.03664315e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(v_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.35977209  0.29158431  0.39087862  0.63980585]\n",
      "  [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      "  [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      "  [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      "  [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      "  [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      "  [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      "  [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      "  [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      "  [ 0.10104732  0.31302565  0.55286384  0.59580714]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.35982227  0.29162312  0.39095309  0.63991541]\n",
      "  [ 0.10104913  0.31306851  0.55296862  0.59590846]\n",
      "  [ 0.10104913  0.31306851  0.55296862  0.59590846]\n",
      "  [ 0.10104913  0.31306851  0.55296862  0.59590846]\n",
      "  [ 0.10104913  0.31306851  0.55296862  0.59590846]\n",
      "  [ 0.10104913  0.31306851  0.55296862  0.59590846]\n",
      "  [ 0.10104913  0.31306851  0.55296862  0.59590846]\n",
      "  [ 0.10104913  0.31306851  0.55296862  0.59590846]\n",
      "  [ 0.10104913  0.31306851  0.55296862  0.59590846]\n",
      "  [ 0.10104913  0.31306851  0.55296862  0.59590846]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.34449691  0.27977133  0.3682006   0.60644704]\n",
      "  [ 0.10049913  0.2999922   0.5209654   0.56495279]\n",
      "  [ 0.10049913  0.2999922   0.5209654   0.56495279]\n",
      "  [ 0.10049913  0.2999922   0.5209654   0.56495279]\n",
      "  [ 0.10049913  0.2999922   0.5209654   0.56495279]\n",
      "  [ 0.10049913  0.2999922   0.5209654   0.56495279]\n",
      "  [ 0.10049913  0.2999922   0.5209654   0.56495279]\n",
      "  [ 0.10049913  0.2999922   0.5209654   0.56495279]\n",
      "  [ 0.10049913  0.2999922   0.5209654   0.56495279]\n",
      "  [ 0.10049913  0.2999922   0.5209654   0.56495279]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.34659481  0.28139371  0.37131515  0.61102849]\n",
      "  [ 0.1005744   0.30178222  0.52534628  0.56919026]\n",
      "  [ 0.1005744   0.30178222  0.52534628  0.56919026]\n",
      "  [ 0.1005744   0.30178222  0.52534628  0.56919026]\n",
      "  [ 0.1005744   0.30178222  0.52534628  0.56919026]\n",
      "  [ 0.1005744   0.30178222  0.52534628  0.56919026]\n",
      "  [ 0.1005744   0.30178222  0.52534628  0.56919026]\n",
      "  [ 0.1005744   0.30178222  0.52534628  0.56919026]\n",
      "  [ 0.1005744   0.30178222  0.52534628  0.56919026]\n",
      "  [ 0.1005744   0.30178222  0.52534628  0.56919026]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.29236639  0.2394565   0.29080606  0.49260154]\n",
      "  [ 0.09862831  0.25551221  0.41210368  0.45965445]\n",
      "  [ 0.09862831  0.25551221  0.41210368  0.45965445]\n",
      "  [ 0.09862831  0.25551221  0.41210368  0.45965445]\n",
      "  [ 0.09862831  0.25551221  0.41210368  0.45965445]\n",
      "  [ 0.09862831  0.25551221  0.41210368  0.45965445]\n",
      "  [ 0.09862831  0.25551221  0.41210368  0.45965445]\n",
      "  [ 0.09862831  0.25551221  0.41210368  0.45965445]\n",
      "  [ 0.09862831  0.25551221  0.41210368  0.45965445]\n",
      "  [ 0.09862831  0.25551221  0.41210368  0.45965445]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.3620072   0.29331279  0.39419687  0.64468688]\n",
      "  [ 0.10112754  0.31493273  0.55753124  0.60032171]\n",
      "  [ 0.10112754  0.31493273  0.55753124  0.60032171]\n",
      "  [ 0.10112754  0.31493273  0.55753124  0.60032171]\n",
      "  [ 0.10112754  0.31493273  0.55753124  0.60032171]\n",
      "  [ 0.10112754  0.31493273  0.55753124  0.60032171]\n",
      "  [ 0.10112754  0.31493273  0.55753124  0.60032171]\n",
      "  [ 0.10112754  0.31493273  0.55753124  0.60032171]\n",
      "  [ 0.10112754  0.31493273  0.55753124  0.60032171]\n",
      "  [ 0.10112754  0.31493273  0.55753124  0.60032171]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.34923774  0.28343764  0.37523898  0.61680037]\n",
      "  [ 0.10066927  0.30403733  0.53086549  0.57452881]\n",
      "  [ 0.10066927  0.30403733  0.53086549  0.57452881]\n",
      "  [ 0.10066927  0.30403733  0.53086549  0.57452881]\n",
      "  [ 0.10066927  0.30403733  0.53086549  0.57452881]\n",
      "  [ 0.10066927  0.30403733  0.53086549  0.57452881]\n",
      "  [ 0.10066927  0.30403733  0.53086549  0.57452881]\n",
      "  [ 0.10066927  0.30403733  0.53086549  0.57452881]\n",
      "  [ 0.10066927  0.30403733  0.53086549  0.57452881]\n",
      "  [ 0.10066927  0.30403733  0.53086549  0.57452881]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.35212475  0.28567028  0.3795251   0.62310511]\n",
      "  [ 0.10077287  0.30650061  0.5368942   0.58036017]\n",
      "  [ 0.10077287  0.30650061  0.5368942   0.58036017]\n",
      "  [ 0.10077287  0.30650061  0.5368942   0.58036017]\n",
      "  [ 0.10077287  0.30650061  0.5368942   0.58036017]\n",
      "  [ 0.10077287  0.30650061  0.5368942   0.58036017]\n",
      "  [ 0.10077287  0.30650061  0.5368942   0.58036017]\n",
      "  [ 0.10077287  0.30650061  0.5368942   0.58036017]\n",
      "  [ 0.10077287  0.30650061  0.5368942   0.58036017]\n",
      "  [ 0.10077287  0.30650061  0.5368942   0.58036017]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.37344265  0.30215636  0.41117433  0.66966033]\n",
      "  [ 0.1015379   0.32468998  0.58141136  0.62342024]\n",
      "  [ 0.1015379   0.32468998  0.58141136  0.62342024]\n",
      "  [ 0.1015379   0.32468998  0.58141136  0.62342024]\n",
      "  [ 0.1015379   0.32468998  0.58141136  0.62342024]\n",
      "  [ 0.1015379   0.32468998  0.58141136  0.62342024]\n",
      "  [ 0.1015379   0.32468998  0.58141136  0.62342024]\n",
      "  [ 0.1015379   0.32468998  0.58141136  0.62342024]\n",
      "  [ 0.1015379   0.32468998  0.58141136  0.62342024]\n",
      "  [ 0.1015379   0.32468998  0.58141136  0.62342024]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.33577198  0.27302396  0.35524726  0.58739299]\n",
      "  [ 0.10018601  0.2925477   0.50274545  0.54732925]\n",
      "  [ 0.10018601  0.2925477   0.50274545  0.54732925]\n",
      "  [ 0.10018601  0.2925477   0.50274545  0.54732925]\n",
      "  [ 0.10018601  0.2925477   0.50274545  0.54732925]\n",
      "  [ 0.10018601  0.2925477   0.50274545  0.54732925]\n",
      "  [ 0.10018601  0.2925477   0.50274545  0.54732925]\n",
      "  [ 0.10018601  0.2925477   0.50274545  0.54732925]\n",
      "  [ 0.10018601  0.2925477   0.50274545  0.54732925]\n",
      "  [ 0.10018601  0.2925477   0.50274545  0.54732925]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]]\n",
      "[[ 0.89286017  0.33197981  0.8212291   0.04169663]\n",
      " [ 0.10765668  0.59505206  0.52981734  0.41880742]\n",
      " [ 0.33540785  0.62251943  0.43814144  0.7358821 ]\n",
      " [ 0.51803643  0.57885861  0.64535511  0.99022424]\n",
      " [ 0.81985819  0.41320094  0.87626767  0.82375944]\n",
      " [ 0.05447451  0.71863723  0.80217057  0.73640662]\n",
      " [ 0.70913178  0.54093683  0.12482417  0.95764732]\n",
      " [ 0.4032563   0.21695116  0.71727586  0.99420744]\n",
      " [ 0.25561404  0.67130941  0.59900594  0.71733212]\n",
      " [ 0.93734956  0.35180977  0.2536341   0.4024725 ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(v_d)\n",
    "print(x_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
